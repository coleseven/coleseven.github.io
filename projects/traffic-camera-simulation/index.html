<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Traffic Camera Simulation</title>
    <link rel="stylesheet" href="/style.css">

</head>
<nav>
    <a href="/">Home</a> |
    <a href="/projects/">Projects</a> |
    <a href="/blog/">Blog</a>
</nav>
<hr>

<body>
    <h1>Traffic Camera Simulation</h1>

    <h2>Overview</h2>
    <p>
        This project comes in two different parts. The first part is the program itself. The second part is the simulation I created to study the intitial program as it has been updated. The program itself takes images from public traffic cameras in the Beaufort area and compiles them into a video daily.
    </p>

    <h2>Program Progression</h2>
    <p>
        The initial version of this program(V1) downloaded images from 35 different cameras in parallel. This program polled every 2 seconds, downloading an image per camera every 2 seconds. V1 had issues with generating large traffic every 2 seconds and as well captured a large amount of duplicate images. V1 had a roughly 99% capture rate of unique images. The second version(V2) of this program used groups of cameras and within each group there is a small phase offset for each camera. For example, inside of a group, the first camera polls, then the second camera polls n seconds after the first, so on and so forth for the number of cameras in a group. This version of the program improved the large traffic spikes V1 had, with a very slight decrease in capture efficency down to 98%. This is due to the offset values. Lastly there is a third version of this program(V3) that I have been planning on implementing. This version of the program is a simple addition of a conditional GET statement to check if an image being downloaded is unique or a duplicate. If it is a duplicate it does not download. This version of the program does not exist yet but I studied it in my simulation of this program. 
    </p>
    <h2>Hardware and Automation</h2>
    <p> On top of creating the software for this project, I as well build a PC that runs this program 24/7. This program is ran on a Windows 10 PC(I would have prefered Linux but the individual I made this for wanted windows). I won't go into detail on the PC specifications but most importantly it has a 256gb SSD and a 6tb HDD. This program is actually 2 separate programs, one is the recorder program, the other is a compiler. The recorder is ran on the CPU, and the compiler utilizes ffmpeg GPU encoding. These programs are set to run using .bat scripts and the Task Scheduler in Windows. Specifically, the camera recorder script is running 24/7, every hour a simple .bat script is ran to verify this program is running and if it is not, then it will reboot the program. Every night at 11:59, the compiler script runs and compilies all of yesterdays images. As well the compiler script removes all images once they are compiled as well as checks to see if there are more than 90 days worth of compiled videos. If it sees that there are more than 90 videos then it will delete the oldest video. The recorder program downloads videos onto the SSD, then the compiler, compiles the images and puts the file on the HDD. This is important for a few different reasons. Firstly, the read/write speed of the SSD are higher than the HDD so when compiling 35 videos, each made up of 24 hours of images being recorded(roughly every 3 seconds), the read/write speed will cause the program to take longer than desired to run. As well, this helped me to cut the cost of the PC down for my client, only needing to use one smaller SSD and a HDD instead of all SSDs. Finally this program runs on boot, the PC itself will autoboot so long as the computer gets power(and the CMOS battery doesn't die). </p>
    <h2>Simulation</h2>
    <p>
        For the final project for Modeling and Simulations, I chose to study this program to see if my updated program made meaningful improvements as well as I looked at if my potential V3 change would as well have meaningful improvements. I used excel and VBA to create this simulation. I used data that I had gathered using some small python helper scripts to determine how often images actually post as well as the average size of the image taken. I created 3 different excel sheets to run each different version of the program(all included in the github repository).
    </p>

    <h2>Results</h2>
    <p>
        The simulations I created showed that from V1 to V2, the traffic burst nature of V1 was removed in favor of a smoother V2. From V2 to V3 the conditional GET statement was very benefitial as it forces the duplicate rate to zero. Which is very useful as I will be able to add more cameras to the program if needed without having to update hardware.
    </p>

    <h2>Tools & Technologies</h2>
    <ul>
        <li>Python</li>
        <li>Excel (VBA)</li>
        <li>Monte Carlo simulation</li>
    </ul>

<h2>Links</h2>
<ul>
    <li>
        <a href="https://github.com/coleseven/Traffic-Camera-Recorder-and-Compiler" target="_blank">
            GitHub Repository
        </a>
    </li>
    <li>
        <a href="https://github.com/coleseven/Traffic-Camera-Recorder-and-Compiler/blob/main/Camera%20Recorder/Model%20Sims/ModSimsFinalZip/Modeling_Sims_Final_Writeup.pdf"
           target="_blank">
            Simulation Paper (PDF)
        </a>
    </li>
</ul>


    <p><a href="/projects/">Back to Projects</a></p>
</body>
</html>
